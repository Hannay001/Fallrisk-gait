{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb15a876",
   "metadata": {},
   "source": [
    "# 04 · Baseline tabular models\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ORG/Fallrisk-gait/blob/main/datasets/fallrisk/notebooks/04_baseline_tabular.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac0ef2",
   "metadata": {},
   "source": [
    "Train pure-Python baselines on the synthetic table: logistic regression and gradient boosting stumps for both the binary high-risk label and the 3-class policy. Report AUROC, macro-F1, calibration curves, and demographic slice metrics (sex and age bands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94195d45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T12:31:46.920958Z",
     "iopub.status.busy": "2025-10-30T12:31:46.920607Z",
     "iopub.status.idle": "2025-10-30T12:31:47.712990Z",
     "shell.execute_reply": "2025-10-30T12:31:47.710605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 synthetic rows\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def locate_repo_root(max_depth: int = 6) -> Path:\n",
    "    here = Path.cwd()\n",
    "    for _ in range(max_depth):\n",
    "        if (here / 'datasets').exists() and (here / 'data').exists():\n",
    "            return here\n",
    "        if here.parent == here:\n",
    "            break\n",
    "        here = here.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "ROOT = locate_repo_root()\n",
    "data_path = ROOT / 'datasets' / 'fallrisk' / 'fallrisk_tabular_v1.csv'\n",
    "with data_path.open() as f:\n",
    "    rows = list(csv.DictReader(f))\n",
    "print(f'Loaded {len(rows)} synthetic rows')\n",
    "random.seed(8)\n",
    "random.shuffle(rows)\n",
    "rows = rows[:15000]\n",
    "split = int(0.8 * len(rows))\n",
    "train_rows = rows[:split]\n",
    "test_rows = rows[split:]\n",
    "FEATURES = ['age_years','bmi','systolic_bp','gait_speed_m_s','postural_sway_cm','medication_count',\n",
    "             'chronic_conditions','past_falls_6mo','dual_task_cost_percent','fear_of_falling_score',\n",
    "             'muscle_strength_score','reaction_time_ms']\n",
    "CLASSES = ['low','moderate','high']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13981d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T12:31:47.718363Z",
     "iopub.status.busy": "2025-10-30T12:31:47.717978Z",
     "iopub.status.idle": "2025-10-30T12:31:47.773873Z",
     "shell.execute_reply": "2025-10-30T12:31:47.770703Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_float(row, key):\n",
    "    return float(row[key])\n",
    "\n",
    "class StandardScaler:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        self.stats = {feature: (0.0, 1.0) for feature in features}\n",
    "\n",
    "    def fit(self, data):\n",
    "        for feat in self.features:\n",
    "            vals = [to_float(r, feat) for r in data]\n",
    "            mean_val = sum(vals) / len(vals)\n",
    "            var = sum((v - mean_val) ** 2 for v in vals) / len(vals)\n",
    "            std = math.sqrt(var) if var > 0 else 1.0\n",
    "            self.stats[feat] = (mean_val, std)\n",
    "\n",
    "    def transform(self, row):\n",
    "        return [(to_float(row, feat) - self.stats[feat][0]) / (self.stats[feat][1] or 1.0) for feat in self.features]\n",
    "\n",
    "def logistic(x):\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, lr=0.12, epochs=120):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.weights = [0.0] * (len(X[0]) + 1)\n",
    "        n = len(X)\n",
    "        for epoch in range(self.epochs):\n",
    "            grad0 = 0.0\n",
    "            grad = [0.0] * len(X[0])\n",
    "            for xi, yi in zip(X, y):\n",
    "                z = self.weights[0] + sum(w * v for w, v in zip(self.weights[1:], xi))\n",
    "                p = logistic(z)\n",
    "                diff = p - yi\n",
    "                grad0 += diff\n",
    "                for j in range(len(xi)):\n",
    "                    grad[j] += diff * xi[j]\n",
    "            step = self.lr / (1 + 0.01 * epoch)\n",
    "            self.weights[0] -= step * grad0 / n\n",
    "            for j in range(len(grad)):\n",
    "                self.weights[j + 1] -= step * grad[j] / n\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = []\n",
    "        for xi in X:\n",
    "            z = self.weights[0] + sum(w * v for w, v in zip(self.weights[1:], xi))\n",
    "            probs.append(logistic(z))\n",
    "        return probs\n",
    "\n",
    "class GradientBoostingStumps:\n",
    "    def __init__(self, n_estimators=18, learning_rate=0.18):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.trees = []\n",
    "        self.base_logit = 0.0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        base_rate = sum(y) / len(y)\n",
    "        base_rate = min(max(base_rate, 1e-6), 1 - 1e-6)\n",
    "        self.base_logit = math.log(base_rate / (1 - base_rate))\n",
    "        preds = [self.base_logit] * len(X)\n",
    "        for _ in range(self.n_estimators):\n",
    "            probs = [logistic(val) for val in preds]\n",
    "            residuals = [yt - pr for yt, pr in zip(y, probs)]\n",
    "            tree = self._fit_stump(X, residuals)\n",
    "            self.trees.append(tree)\n",
    "            for i, xi in enumerate(X):\n",
    "                update = tree['left_value'] if xi[tree['feature']] <= tree['threshold'] else tree['right_value']\n",
    "                preds[i] += self.learning_rate * update\n",
    "\n",
    "    def _fit_stump(self, X, residuals):\n",
    "        best = {'loss': float('inf')}\n",
    "        total_sum = sum(residuals)\n",
    "        total_sq = sum(r * r for r in residuals)\n",
    "        total_count = len(residuals)\n",
    "        n_features = len(X[0])\n",
    "        for feat in range(n_features):\n",
    "            pairs = sorted(((xi[feat], res) for xi, res in zip(X, residuals)), key=lambda x: x[0])\n",
    "            prefix_sum = 0.0\n",
    "            prefix_sq = 0.0\n",
    "            prefix_count = 0\n",
    "            for i in range(len(pairs) - 1):\n",
    "                val, res = pairs[i]\n",
    "                prefix_sum += res\n",
    "                prefix_sq += res * res\n",
    "                prefix_count += 1\n",
    "                if pairs[i + 1][0] == val:\n",
    "                    continue\n",
    "                left_count = prefix_count\n",
    "                right_count = total_count - prefix_count\n",
    "                if left_count == 0 or right_count == 0:\n",
    "                    continue\n",
    "                left_sum = prefix_sum\n",
    "                right_sum = total_sum - prefix_sum\n",
    "                left_sq = prefix_sq\n",
    "                right_sq = total_sq - prefix_sq\n",
    "                left_mean = left_sum / left_count\n",
    "                right_mean = right_sum / right_count\n",
    "                left_loss = left_sq - left_sum * left_sum / left_count\n",
    "                right_loss = right_sq - right_sum * right_sum / right_count\n",
    "                loss = left_loss + right_loss\n",
    "                if loss < best['loss']:\n",
    "                    threshold = (val + pairs[i + 1][0]) / 2.0\n",
    "                    best = {\n",
    "                        'feature': feat,\n",
    "                        'threshold': threshold,\n",
    "                        'left_value': left_mean,\n",
    "                        'right_value': right_mean,\n",
    "                        'loss': loss\n",
    "                    }\n",
    "        if best['loss'] == float('inf'):\n",
    "            best = {'feature': 0, 'threshold': 0.0, 'left_value': 0.0, 'right_value': 0.0, 'loss': 0.0}\n",
    "        return best\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = []\n",
    "        for xi in X:\n",
    "            logit_val = self.base_logit\n",
    "            for tree in self.trees:\n",
    "                update = tree['left_value'] if xi[tree['feature']] <= tree['threshold'] else tree['right_value']\n",
    "                logit_val += self.learning_rate * update\n",
    "            probs.append(logistic(logit_val))\n",
    "        return probs\n",
    "\n",
    "def auc_score(probs, labels):\n",
    "    pairs = sorted(zip(probs, labels), key=lambda x: x[0])\n",
    "    pos = sum(labels)\n",
    "    neg = len(labels) - pos\n",
    "    if pos == 0 or neg == 0:\n",
    "        return None\n",
    "    rank = 0.0\n",
    "    cum_pos = 0\n",
    "    for idx, (score, label) in enumerate(pairs, start=1):\n",
    "        if label == 1:\n",
    "            rank += idx\n",
    "            cum_pos += 1\n",
    "    return (rank - cum_pos * (cum_pos + 1) / 2) / (pos * neg)\n",
    "\n",
    "def macro_f1(labels, preds):\n",
    "    cm = Counter()\n",
    "    for yt, yp in zip(labels, preds):\n",
    "        cm[(yt, yp)] += 1\n",
    "    def f1_for(target):\n",
    "        tp = cm[(target, target)]\n",
    "        fp = cm[(1 - target, target)]\n",
    "        fn = cm[(target, 1 - target)]\n",
    "        precision = tp / (tp + fp) if tp + fp else 0.0\n",
    "        recall = tp / (tp + fn) if tp + fn else 0.0\n",
    "        return 0.0 if precision + recall == 0 else 2 * precision * recall / (precision + recall)\n",
    "    return 0.5 * (f1_for(0) + f1_for(1))\n",
    "\n",
    "\n",
    "def brier_score(probs, labels):\n",
    "    if not labels:\n",
    "        return 0.0\n",
    "    return sum((p - y) ** 2 for p, y in zip(probs, labels)) / len(labels)\n",
    "\n",
    "def preview_calibration(curve, max_bins=3):\n",
    "    preview = []\n",
    "    for entry in curve:\n",
    "        if entry['count']:\n",
    "            preview.append(entry)\n",
    "        if len(preview) >= max_bins:\n",
    "            break\n",
    "    return preview\n",
    "\n",
    "def calibration_curve(probs, labels, bins=10):\n",
    "    counts = [0] * bins\n",
    "    prob_sum = [0.0] * bins\n",
    "    label_sum = [0.0] * bins\n",
    "    for p, y in zip(probs, labels):\n",
    "        idx = min(bins - 1, int(p * bins))\n",
    "        counts[idx] += 1\n",
    "        prob_sum[idx] += p\n",
    "        label_sum[idx] += y\n",
    "    curve = []\n",
    "    for i in range(bins):\n",
    "        if counts[i] == 0:\n",
    "            curve.append({'bin': i, 'count': 0, 'pred': None, 'actual': None})\n",
    "        else:\n",
    "            curve.append({'bin': i, 'count': counts[i], 'pred': prob_sum[i] / counts[i], 'actual': label_sum[i] / counts[i]})\n",
    "    return curve\n",
    "\n",
    "def slice_macro_f1(rows, probs, labels, threshold=0.5):\n",
    "    grouped = defaultdict(list)\n",
    "    for row, prob, label in zip(rows, probs, labels):\n",
    "        age = float(row['age_years'])\n",
    "        if age < 70:\n",
    "            age_group = '<70'\n",
    "        elif age < 80:\n",
    "            age_group = '70-79'\n",
    "        else:\n",
    "            age_group = '80+'\n",
    "        grouped[('sex', row['sex'])].append((prob, label))\n",
    "        grouped[('age_group', age_group)].append((prob, label))\n",
    "    metrics = {}\n",
    "    for key, items in grouped.items():\n",
    "        preds = [1 if p >= threshold else 0 for p, _ in items]\n",
    "        true = [y for _, y in items]\n",
    "        metrics[key] = {\n",
    "            'count': len(items),\n",
    "            'macro_f1': round(macro_f1(true, preds), 3)\n",
    "        }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c79af3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T12:31:47.778900Z",
     "iopub.status.busy": "2025-10-30T12:31:47.778442Z",
     "iopub.status.idle": "2025-10-30T12:31:54.383807Z",
     "shell.execute_reply": "2025-10-30T12:31:54.382374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression → AUROC: 0.927, macro-F1: 0.858, Brier: 0.111\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(FEATURES)\n",
    "scaler.fit(train_rows)\n",
    "X_train = [scaler.transform(r) for r in train_rows]\n",
    "y_train = [int(r['label_high_fall_risk']) for r in train_rows]\n",
    "X_test = [scaler.transform(r) for r in test_rows]\n",
    "y_test = [int(r['label_high_fall_risk']) for r in test_rows]\n",
    "\n",
    "logreg = BinaryLogisticRegression(lr=0.15, epochs=140)\n",
    "logreg.fit(X_train, y_train)\n",
    "log_probs = logreg.predict_proba(X_test)\n",
    "log_preds = [1 if p >= 0.5 else 0 for p in log_probs]\n",
    "log_auc = auc_score(log_probs, y_test)\n",
    "log_macro_f1 = macro_f1(y_test, log_preds)\n",
    "log_brier = brier_score(log_probs, y_test)\n",
    "print(f'Logistic regression → AUROC: {log_auc:.3f}, macro-F1: {log_macro_f1:.3f}, Brier: {log_brier:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44eb8b74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T12:31:54.386907Z",
     "iopub.status.busy": "2025-10-30T12:31:54.386547Z",
     "iopub.status.idle": "2025-10-30T12:31:56.810913Z",
     "shell.execute_reply": "2025-10-30T12:31:56.809764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting stumps → AUROC: 0.855, macro-F1: 0.849, Brier: 0.145\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingStumps()\n",
    "gb.fit(X_train, y_train)\n",
    "gb_probs = gb.predict_proba(X_test)\n",
    "gb_preds = [1 if p >= 0.5 else 0 for p in gb_probs]\n",
    "gb_auc = auc_score(gb_probs, y_test)\n",
    "gb_macro_f1 = macro_f1(y_test, gb_preds)\n",
    "gb_brier = brier_score(gb_probs, y_test)\n",
    "print(f'Gradient boosting stumps → AUROC: {gb_auc:.3f}, macro-F1: {gb_macro_f1:.3f}, Brier: {gb_brier:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd33f71f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T12:31:56.814395Z",
     "iopub.status.busy": "2025-10-30T12:31:56.814083Z",
     "iopub.status.idle": "2025-10-30T12:31:56.824853Z",
     "shell.execute_reply": "2025-10-30T12:31:56.823674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic calibration bin {'bin': 0, 'count': 104, 'pred': 0.0770487975918477, 'actual': 0.028846153846153848}\n",
      "Logistic calibration bin {'bin': 1, 'count': 561, 'pred': 0.15323240117049364, 'actual': 0.09269162210338681}\n",
      "Logistic calibration bin {'bin': 2, 'count': 535, 'pred': 0.24890581777512216, 'actual': 0.16448598130841122}\n",
      "Gradient boosting calibration bin {'bin': 3, 'count': 1936, 'pred': 0.35517613943727594, 'actual': 0.22882231404958678}\n",
      "Gradient boosting calibration bin {'bin': 7, 'count': 1064, 'pred': 0.7597561277917732, 'actual': 1.0}\n"
     ]
    }
   ],
   "source": [
    "log_calibration = calibration_curve(log_probs, y_test)\n",
    "for entry in preview_calibration(log_calibration):\n",
    "    print('Logistic calibration bin', entry)\n",
    "\n",
    "gb_calibration = calibration_curve(gb_probs, y_test)\n",
    "for entry in preview_calibration(gb_calibration):\n",
    "    print('Gradient boosting calibration bin', entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd7a558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T12:31:56.827727Z",
     "iopub.status.busy": "2025-10-30T12:31:56.827419Z",
     "iopub.status.idle": "2025-10-30T12:31:56.845696Z",
     "shell.execute_reply": "2025-10-30T12:31:56.843644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice ('sex', 'Female') → {'count': 1907, 'macro_f1': 0.855}\n",
      "Slice ('age_group', '70-79') → {'count': 1364, 'macro_f1': 0.866}\n",
      "Slice ('age_group', '80+') → {'count': 402, 'macro_f1': 0.838}\n",
      "Slice ('age_group', '<70') → {'count': 1234, 'macro_f1': 0.853}\n",
      "Slice ('sex', 'Male') → {'count': 1093, 'macro_f1': 0.863}\n"
     ]
    }
   ],
   "source": [
    "slices = slice_macro_f1(test_rows, log_probs, y_test)\n",
    "for key, info in slices.items():\n",
    "    print('Slice', key, '→', info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d19271c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T12:31:56.849045Z",
     "iopub.status.busy": "2025-10-30T12:31:56.848727Z",
     "iopub.status.idle": "2025-10-30T12:31:56.872590Z",
     "shell.execute_reply": "2025-10-30T12:31:56.870499Z"
    }
   },
   "outputs": [],
   "source": [
    "class OneVsRestLogistic:\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "        self.models = {}\n",
    "\n",
    "    def fit(self, X, labels):\n",
    "        for cls in self.classes:\n",
    "            binary = [1 if label == cls else 0 for label in labels]\n",
    "            model = BinaryLogisticRegression(lr=0.12, epochs=120)\n",
    "            model.fit(X, binary)\n",
    "            self.models[cls] = model\n",
    "\n",
    "    def predict(self, X):\n",
    "        outputs = []\n",
    "        for xi in X:\n",
    "            scores = {}\n",
    "            for cls, model in self.models.items():\n",
    "                score = model.predict_proba([xi])[0]\n",
    "                scores[cls] = score\n",
    "            total = sum(scores.values())\n",
    "            if total == 0:\n",
    "                probs = {cls: 1.0 / len(self.classes) for cls in self.classes}\n",
    "            else:\n",
    "                probs = {cls: val / total for cls, val in scores.items()}\n",
    "            outputs.append(probs)\n",
    "        return outputs\n",
    "\n",
    "class OneVsRestGB:\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "        self.models = {}\n",
    "\n",
    "    def fit(self, X, labels):\n",
    "        for cls in self.classes:\n",
    "            binary = [1 if label == cls else 0 for label in labels]\n",
    "            model = GradientBoostingStumps()\n",
    "            model.fit(X, binary)\n",
    "            self.models[cls] = model\n",
    "\n",
    "    def predict(self, X):\n",
    "        outputs = []\n",
    "        for xi in X:\n",
    "            scores = {}\n",
    "            for cls, model in self.models.items():\n",
    "                score = model.predict_proba([xi])[0]\n",
    "                scores[cls] = score\n",
    "            total = sum(scores.values())\n",
    "            if total == 0:\n",
    "                probs = {cls: 1.0 / len(self.classes) for cls in self.classes}\n",
    "            else:\n",
    "                probs = {cls: val / total for cls, val in scores.items()}\n",
    "            outputs.append(probs)\n",
    "        return outputs\n",
    "\n",
    "def macro_f1_multiclass(true_labels, pred_labels):\n",
    "    scores = []\n",
    "    for cls in CLASSES:\n",
    "        tp = sum(1 for yt, yp in zip(true_labels, pred_labels) if yt == cls and yp == cls)\n",
    "        fp = sum(1 for yt, yp in zip(true_labels, pred_labels) if yt != cls and yp == cls)\n",
    "        fn = sum(1 for yt, yp in zip(true_labels, pred_labels) if yt == cls and yp != cls)\n",
    "        precision = tp / (tp + fp) if tp + fp else 0.0\n",
    "        recall = tp / (tp + fn) if tp + fn else 0.0\n",
    "        f1 = 0.0 if precision + recall == 0 else 2 * precision * recall / (precision + recall)\n",
    "        scores.append(f1)\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "def multiclass_auc(true_labels, prob_dicts):\n",
    "    aucs = []\n",
    "    for cls in CLASSES:\n",
    "        binary_true = [1 if label == cls else 0 for label in true_labels]\n",
    "        binary_scores = [prob[cls] for prob in prob_dicts]\n",
    "        auc = auc_score(binary_scores, binary_true)\n",
    "        if auc is not None:\n",
    "            aucs.append(auc)\n",
    "    return sum(aucs) / len(aucs) if aucs else None\n",
    "\n",
    "def multiclass_brier(prob_dicts, true_labels):\n",
    "    if not true_labels:\n",
    "        return 0.0\n",
    "    total = 0.0\n",
    "    for probs, label in zip(prob_dicts, true_labels):\n",
    "        for cls in CLASSES:\n",
    "            target = 1.0 if label == cls else 0.0\n",
    "            total += (probs.get(cls, 0.0) - target) ** 2\n",
    "    return total / (len(true_labels) * len(CLASSES))\n",
    "\n",
    "def multiclass_calibration(prob_dicts, true_labels, bins=10):\n",
    "    curves = {}\n",
    "    for cls in CLASSES:\n",
    "        binary_labels = [1 if label == cls else 0 for label in true_labels]\n",
    "        binary_probs = [prob.get(cls, 0.0) for prob in prob_dicts]\n",
    "        curves[cls] = calibration_curve(binary_probs, binary_labels, bins=bins)\n",
    "    return curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30134506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T12:31:56.875710Z",
     "iopub.status.busy": "2025-10-30T12:31:56.875399Z",
     "iopub.status.idle": "2025-10-30T12:32:12.158103Z",
     "shell.execute_reply": "2025-10-30T12:32:12.156509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic OvR (3-class) → AUROC: 0.904, macro-F1: 0.744, Brier: 0.126\n",
      "Logistic OvR calibration (low) → [{'bin': 0, 'count': 572, 'pred': 0.05592938313651174, 'actual': 0.0}, {'bin': 1, 'count': 595, 'pred': 0.14753184538716943, 'actual': 0.01680672268907563}, {'bin': 2, 'count': 536, 'pred': 0.2498730316172001, 'actual': 0.11380597014925373}]\n",
      "Logistic OvR calibration (moderate) → [{'bin': 0, 'count': 481, 'pred': 0.05926155340742506, 'actual': 0.004158004158004158}, {'bin': 1, 'count': 676, 'pred': 0.15131315686310884, 'actual': 0.04881656804733728}, {'bin': 2, 'count': 615, 'pred': 0.2469281899248761, 'actual': 0.12032520325203253}]\n",
      "Logistic OvR calibration (high) → [{'bin': 0, 'count': 102, 'pred': 0.07640565299507092, 'actual': 0.029411764705882353}, {'bin': 1, 'count': 519, 'pred': 0.15404200657938072, 'actual': 0.09248554913294797}, {'bin': 2, 'count': 545, 'pred': 0.2498871955862063, 'actual': 0.1596330275229358}]\n"
     ]
    }
   ],
   "source": [
    "train_labels = [row['label_risk_level'] for row in train_rows]\n",
    "test_labels = [row['label_risk_level'] for row in test_rows]\n",
    "ovr_logreg = OneVsRestLogistic(CLASSES)\n",
    "ovr_logreg.fit(X_train, train_labels)\n",
    "log_multi_probs = ovr_logreg.predict(X_test)\n",
    "log_multi_preds = [max(prob.items(), key=lambda x: x[1])[0] for prob in log_multi_probs]\n",
    "log_multi_f1 = macro_f1_multiclass(test_labels, log_multi_preds)\n",
    "log_multi_auc = multiclass_auc(test_labels, log_multi_probs)\n",
    "log_multi_brier = multiclass_brier(log_multi_probs, test_labels)\n",
    "log_multi_calibration = multiclass_calibration(log_multi_probs, test_labels)\n",
    "print(f'Logistic OvR (3-class) → AUROC: {log_multi_auc:.3f}, macro-F1: {log_multi_f1:.3f}, Brier: {log_multi_brier:.3f}')\n",
    "for cls in CLASSES:\n",
    "    preview = preview_calibration(log_multi_calibration[cls])\n",
    "    if preview:\n",
    "        print(f'Logistic OvR calibration ({cls}) → {preview}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01ac9d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T12:32:12.161788Z",
     "iopub.status.busy": "2025-10-30T12:32:12.161478Z",
     "iopub.status.idle": "2025-10-30T12:32:19.772287Z",
     "shell.execute_reply": "2025-10-30T12:32:19.770441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting OvR (3-class) → AUROC: 0.874, macro-F1: 0.467, Brier: 0.156\n",
      "Gradient boosting OvR calibration (low) → [{'bin': 1, 'count': 1064, 'pred': 0.1683039198555955, 'actual': 0.0}, {'bin': 2, 'count': 652, 'pred': 0.23582172774482116, 'actual': 0.0}, {'bin': 3, 'count': 1284, 'pred': 0.3474339394037014, 'actual': 0.6043613707165109}]\n",
      "Gradient boosting OvR calibration (moderate) → [{'bin': 1, 'count': 697, 'pred': 0.14020444013746677, 'actual': 0.0}, {'bin': 2, 'count': 1651, 'pred': 0.25830674108716206, 'actual': 0.14173228346456693}, {'bin': 3, 'count': 652, 'pred': 0.3829117394349736, 'actual': 0.74079754601227}]\n",
      "Gradient boosting OvR calibration (high) → [{'bin': 3, 'count': 1936, 'pred': 0.3801174610769205, 'actual': 0.22882231404958678}, {'bin': 6, 'count': 1064, 'pred': 0.6685252833857224, 'actual': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "ovr_gb = OneVsRestGB(CLASSES)\n",
    "ovr_gb.fit(X_train, train_labels)\n",
    "gb_multi_probs = ovr_gb.predict(X_test)\n",
    "gb_multi_preds = [max(prob.items(), key=lambda x: x[1])[0] for prob in gb_multi_probs]\n",
    "gb_multi_f1 = macro_f1_multiclass(test_labels, gb_multi_preds)\n",
    "gb_multi_auc = multiclass_auc(test_labels, gb_multi_probs)\n",
    "gb_multi_brier = multiclass_brier(gb_multi_probs, test_labels)\n",
    "gb_multi_calibration = multiclass_calibration(gb_multi_probs, test_labels)\n",
    "print(f'Gradient boosting OvR (3-class) → AUROC: {gb_multi_auc:.3f}, macro-F1: {gb_multi_f1:.3f}, Brier: {gb_multi_brier:.3f}')\n",
    "for cls in CLASSES:\n",
    "    preview = preview_calibration(gb_multi_calibration[cls])\n",
    "    if preview:\n",
    "        print(f'Gradient boosting OvR calibration ({cls}) → {preview}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
